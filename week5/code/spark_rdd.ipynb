{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a070dd1",
   "metadata": {},
   "source": [
    "### Importing Required Depeendencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23e72a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b7ba9",
   "metadata": {},
   "source": [
    "### Starting Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb415af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/Naveen/spark/spark-3.0.3-bin-hadoop3.2/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/06/09 08:13:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/09 08:13:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName('test') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a762e983",
   "metadata": {},
   "source": [
    "### Map and Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e781dc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('data/pq/green/*/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b6357",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT\n",
    "  date_trunc('hour', lpep_pickup_datetime) AS hour,\n",
    "  PULocationID AS zone,  \n",
    "\n",
    "  SUM(total_amount) AS amount,\n",
    "  COUNT(1) AS number_records\n",
    "\n",
    "FROM \n",
    "    green\n",
    "WHERE \n",
    "    lpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY \n",
    "    1, 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4f5698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 11, 4, 5, 54), lpep_dropoff_datetime=datetime.datetime(2020, 1, 11, 4, 13, 49), store_and_fwd_flag='N', RatecodeID=1.0, PULocationID=129, DOLocationID=129, passenger_count=1.0, trip_distance=0.81, fare_amount=6.5, extra=0.5, mta_tax=0.5, tip_amount=0.71, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=8.51, payment_type=1.0, trip_type=1.0, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 17, 19, 33, 5), lpep_dropoff_datetime=datetime.datetime(2020, 1, 17, 19, 51, 8), store_and_fwd_flag='N', RatecodeID=1.0, PULocationID=75, DOLocationID=42, passenger_count=3.0, trip_distance=2.69, fare_amount=13.5, extra=1.0, mta_tax=0.5, tip_amount=3.06, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=18.36, payment_type=1.0, trip_type=1.0, congestion_surcharge=0.0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b92f38c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = df_green \\\n",
    "    .select('lpep_pickup_datetime', 'PULocationID', 'total_amount') \\\n",
    "    .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a619df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 11, 4, 5, 54), PULocationID=129, total_amount=8.51),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 17, 19, 33, 5), PULocationID=75, total_amount=18.36)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "536d412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2021, 10, 30, 11, 55, 9), PULocationID=33, total_amount=25.86),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2021, 10, 7, 16, 12), PULocationID=71, total_amount=22.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = datetime(year=2021, month=1, day=1)\n",
    "\n",
    "rdd \\\n",
    "    .filter(lambda row: row.lpep_pickup_datetime >= start) \\\n",
    "    .take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f4e3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(year=2020, month=1, day=1)\n",
    "RevenueRow = namedtuple('RevenueRow', ['hour', 'zone', 'revenue', 'count'])\n",
    "\n",
    "# Filtering data before 2020\n",
    "def filter_outliers(row):\n",
    "    return row.lpep_pickup_datetime >= start\n",
    "\n",
    "# Mapping Key-Value pairs\n",
    "def prepare_for_grouping(row):\n",
    "    hour = row.lpep_pickup_datetime.replace(minute=0, second=0, microsecond=0)\n",
    "    zone = row.PULocationID\n",
    "    key = (hour, zone)\n",
    "    \n",
    "    amount = row.total_amount\n",
    "    count = 1\n",
    "    value = (amount, count)\n",
    "    \n",
    "    return (key, value)\n",
    "\n",
    "# Grouping based on keys\n",
    "def calculate_revenue(left_value, right_value):\n",
    "    left_amount, left_count = left_value\n",
    "    right_amount, right_count = right_value\n",
    "    \n",
    "    output_amount = left_amount + right_amount\n",
    "    output_count = left_count + right_count\n",
    "    \n",
    "    return (output_amount, output_count)\n",
    "\n",
    "# Unwrapping key-value pairs to a single row\n",
    "def unwrap(row):    \n",
    "    return RevenueRow(\n",
    "        hour = row[0][0], \n",
    "        zone = row[0][1], \n",
    "        revenue = row[1][0], \n",
    "        count = row[1][1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "186a230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+-----+\n",
      "|               hour|zone|           revenue|count|\n",
      "+-------------------+----+------------------+-----+\n",
      "|2020-01-04 21:00:00| 129|471.95000000000016|   34|\n",
      "|2020-01-21 06:00:00|  37|             86.45|    3|\n",
      "|2020-01-03 16:00:00|   7| 413.2300000000001|   33|\n",
      "|2020-01-06 17:00:00|  82| 823.4299999999997|   56|\n",
      "|2020-01-20 15:00:00| 155|             76.34|    3|\n",
      "|2020-01-23 17:00:00|  75|1581.9899999999977|  103|\n",
      "|2020-01-11 18:00:00|  25|254.21000000000004|   18|\n",
      "|2020-01-16 18:00:00|  91|             71.03|    3|\n",
      "|2020-01-04 13:00:00|  66|252.98000000000008|   17|\n",
      "|2020-01-03 19:00:00| 181|            171.49|   15|\n",
      "|2020-01-05 08:00:00| 166|             81.36|    4|\n",
      "|2020-01-13 22:00:00|  97|            211.24|   15|\n",
      "|2020-01-02 07:00:00| 260|            168.06|    9|\n",
      "|2020-01-11 15:00:00|  83|            134.48|    9|\n",
      "|2020-01-10 12:00:00| 173|             34.82|    2|\n",
      "|2020-01-12 13:00:00| 244|             286.1|   14|\n",
      "|2020-01-30 15:00:00|  75| 1500.909999999999|   87|\n",
      "|2020-01-01 23:00:00|  41|            247.81|   14|\n",
      "|2020-01-19 17:00:00|  42| 286.7700000000001|   26|\n",
      "|2020-01-05 15:00:00|  17|            135.96|    7|\n",
      "+-------------------+----+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performing Group by on the RDD\n",
    "\n",
    "rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cc04f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Performing group by and converting into a spark dataframe without providing schema\n",
    "# Here spark tries to figure out the schema and goes through various stages and builds the whole rdd\n",
    "\n",
    "df_result = rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f743f164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(hour,TimestampType,true),StructField(zone,LongType,true),StructField(revenue,DoubleType,true),StructField(count,LongType,true)))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81733f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Schema based on the columns shown above\n",
    "from pyspark.sql import types\n",
    "\n",
    "result_schema = types.StructType([\n",
    "  types.StructField('hour', types.TimestampType(), True),\n",
    "  types.StructField('zone', types.IntegerType(), True),\n",
    "  types.StructField('revenue', types.DoubleType(), True),\n",
    "  types.StructField('count', types.IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e6b0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing group by and converting into a spark dataframe while providing schema\n",
    "# Here spark just executes the command without going through the various stages\n",
    "\n",
    "df_result = rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF(result_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d5b9a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+-----+\n",
      "|               hour|zone|           revenue|count|\n",
      "+-------------------+----+------------------+-----+\n",
      "|2020-01-04 21:00:00| 129|471.95000000000016|   34|\n",
      "|2020-01-21 06:00:00|  37|             86.45|    3|\n",
      "|2020-01-03 16:00:00|   7| 413.2300000000001|   33|\n",
      "|2020-01-06 17:00:00|  82| 823.4299999999997|   56|\n",
      "|2020-01-20 15:00:00| 155|             76.34|    3|\n",
      "+-------------------+----+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33387c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Writing the result in a parquet file\n",
    "df_result.write.parquet('tmp/green-revenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a0616",
   "metadata": {},
   "source": [
    "### Map Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af30e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a set of columns to create a new RDD\n",
    "\n",
    "columns = ['VendorID', 'PULocationID', 'DOLocationID', 'trip_distance']\n",
    "\n",
    "duration_rdd = df_green \\\n",
    "    .select(columns) \\\n",
    "    .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d774a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>42</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>188</td>\n",
       "      <td>13.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>151</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>260</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>232</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>168</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>5.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID  PULocationID  DOLocationID  trip_distance\n",
       "0         2           129           129           0.81\n",
       "1         2            75            42           2.69\n",
       "2         2           117           188          13.11\n",
       "3         2            41           151           2.13\n",
       "4         2           129           260           0.89\n",
       "5         2            75            75           0.88\n",
       "6         2            66           232           2.25\n",
       "7         2           129           129           0.91\n",
       "8         2            41           168           2.69\n",
       "9         2            37            33           5.35"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing this rdd as a pandas dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "rows = duration_rdd.take(10)\n",
    "pd.DataFrame(rows, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45c089a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the following model to predict trip duration\n",
    "def model_predict(df):\n",
    "    return df['trip_distance']*5\n",
    "\n",
    "# Applying the above model to a partition\n",
    "def apply_model_in_batch(rows):\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    predictions = model_predict(df)\n",
    "    df['predicted_duration'] = predictions\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4914ea29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Pandas(Index=0, VendorID=2, PULocationID=129, DOLocationID=129, trip_distance=0.81, predicted_duration=4.050000000000001),\n",
       " Pandas(Index=1, VendorID=2, PULocationID=75, DOLocationID=42, trip_distance=2.69, predicted_duration=13.45),\n",
       " Pandas(Index=2, VendorID=2, PULocationID=117, DOLocationID=188, trip_distance=13.11, predicted_duration=65.55),\n",
       " Pandas(Index=3, VendorID=2, PULocationID=41, DOLocationID=151, trip_distance=2.13, predicted_duration=10.649999999999999),\n",
       " Pandas(Index=4, VendorID=2, PULocationID=129, DOLocationID=260, trip_distance=0.89, predicted_duration=4.45)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below code applies the model to each partition/batch\n",
    "duration_rdd \\\n",
    "    .mapPartitions(apply_model_in_batch) \\\n",
    "    .take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23f743f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Providing schema for writing the RDD into a dataframe\n",
    "\n",
    "from pyspark.sql import types\n",
    "\n",
    "predict_schema = types.StructType([\n",
    "    types.StructField('Index', types.IntegerType(), True),\n",
    "    types.StructField('VendorID', types.IntegerType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('trip_distance', types.DoubleType(), True),\n",
    "    types.StructField('predicted_duration', types.DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92732d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = duration_rdd \\\n",
    "    .mapPartitions(apply_model_in_batch) \\\n",
    "    .toDF(predict_schema) \\\n",
    "    .drop('Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "969e55e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 20:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------------+-------------+------------------+\n",
      "|VendorID|PULocationID|DOLocationID|trip_distance|predicted_duration|\n",
      "+--------+------------+------------+-------------+------------------+\n",
      "|       2|         129|         129|         0.81| 4.050000000000001|\n",
      "|       2|          75|          42|         2.69|             13.45|\n",
      "|       2|         117|         188|        13.11|             65.55|\n",
      "|       2|          41|         151|         2.13|10.649999999999999|\n",
      "|       2|         129|         260|         0.89|              4.45|\n",
      "|       2|          75|          75|         0.88|               4.4|\n",
      "|       2|          66|         232|         2.25|             11.25|\n",
      "|       2|         129|         129|         0.91|              4.55|\n",
      "|       2|          41|         168|         2.69|             13.45|\n",
      "|       2|          37|          33|         5.35|             26.75|\n",
      "+--------+------------+------------+-------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_predict.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4209d3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
